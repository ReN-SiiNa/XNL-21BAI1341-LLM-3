{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Simulating the Database**"
      ],
      "metadata": {
        "id": "nkEKWu4wiaDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcnLY79ghV1I",
        "outputId": "81c2bba4-a673-4a0e-b141-48fb24efd13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faker pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import uuid\n",
        "from faker import Faker\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jjuMVRGmitIa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Define Regions\n",
        "REGIONS = [\"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\"]\n",
        "BROWSERS = [\"Chrome\", \"Firefox\", \"Safari\", \"Edge\", \"Brave\"]\n",
        "DEVICE_TYPES = [\"Mobile\", \"Desktop\", \"Tablet\"]\n",
        "\n",
        "# Define Merchant Categories\n",
        "MERCHANTS = {\n",
        "    \"Groceries\": [\"Walmart\", \"Whole Foods\", \"Trader Joe's\", \"Costco\"],\n",
        "    \"Electronics\": [\"Best Buy\", \"Apple Store\", \"Newegg\"],\n",
        "    \"Travel\": [\"Uber\", \"Lyft\", \"Airbnb\", \"Delta Airlines\"],\n",
        "    \"Clothing\": [\"Nike\", \"Adidas\", \"H&M\", \"Zara\"],\n",
        "    \"Entertainment\": [\"Netflix\", \"Spotify\", \"AMC Theatres\"],\n",
        "    \"Dining\": [\"McDonald's\", \"Starbucks\", \"Chipotle\"],\n",
        "    \"Gas\": [\"Shell\", \"Exxon\", \"Chevron\"],\n",
        "    \"Health\": [\"CVS Pharmacy\", \"Walgreens\", \"Rite Aid\"]\n",
        "}"
      ],
      "metadata": {
        "id": "5Z3TtTZ-iwFt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a synthetic transaction\n",
        "def generate_transaction(user_id, is_fraud=False):\n",
        "    amount = round(random.uniform(5, 5000), 2)\n",
        "    category = random.choice(list(MERCHANTS.keys()))\n",
        "    merchant = random.choice(MERCHANTS[category])\n",
        "    location = fake.city()\n",
        "    timestamp = fake.date_time_between(start_date=\"-90d\", end_date=\"now\")\n",
        "    ip_address = fake.ipv4()\n",
        "    browser = random.choice(BROWSERS)\n",
        "    device_type = random.choice(DEVICE_TYPES)\n",
        "    session_metadata = f\"Latency: {random.randint(10, 500)}ms | Device: {device_type} | Browser: {browser}\"\n",
        "\n",
        "    # Fraudulent transaction modifications\n",
        "    fraud_flag = 0  # Normal\n",
        "    if is_fraud:\n",
        "        amount *= random.uniform(2, 10)  # Inflate amount\n",
        "        location = fake.city()  # Different location\n",
        "        ip_address = fake.ipv4_private()  # Private IP (hidden)\n",
        "        fraud_flag = 1  # Fraudulent\n",
        "\n",
        "    return {\n",
        "        \"transaction_id\": str(uuid.uuid4()),\n",
        "        \"user_id\": user_id,\n",
        "        \"amount\": amount,\n",
        "        \"timestamp\": timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"merchant\": merchant,\n",
        "        \"category\": category,\n",
        "        \"location\": location,\n",
        "        \"ip_address\": ip_address,\n",
        "        \"browser\": browser,\n",
        "        \"device_type\": device_type,\n",
        "        \"session_metadata\": session_metadata,\n",
        "        \"fraud_flag\": fraud_flag\n",
        "    }"
      ],
      "metadata": {
        "id": "-Sy63IDcif69"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Users\n",
        "num_users = 10000  # 10K Users\n",
        "users = [{\"user_id\": i, \"age\": random.randint(18, 75), \"region\": random.choice(REGIONS), \"credit_score\": random.randint(300, 850)} for i in range(num_users)]\n",
        "\n",
        "# Generate Transactions\n",
        "num_transactions = 1000000  # 1M Transactions\n",
        "fraud_ratio = 0.1  # 10% fraud transactions\n",
        "\n",
        "transactions = []\n",
        "for _ in tqdm(range(num_transactions), desc=\"Generating Transactions\"):\n",
        "    user_id = random.randint(0, num_users - 1)\n",
        "    is_fraud = random.random() < fraud_ratio\n",
        "    transactions.append(generate_transaction(user_id, is_fraud))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(transactions)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"synthetic_transactions.csv\", index=False)\n",
        "\n",
        "print(\"Dataset generated and saved as 'synthetic_transactions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSX6RCEci2TQ",
        "outputId": "0bd472d6-794c-42f2-c7a6-77e3fba5bdd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Transactions: 100%|██████████| 1000000/1000000 [04:54<00:00, 3390.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated and saved as 'synthetic_transactions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "PF8uX9opr9QS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "arsCTssXlVal",
        "outputId": "53dc3d0a-f599-441d-c8d9-fa319fff7314"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         transaction_id  user_id   amount  \\\n",
              "0  fc12e211-cd56-4394-a4c6-dc1c360b4ff4     1956  4105.52   \n",
              "1  13f84663-5bc5-4b5f-9146-eb42c2e63876     8666  4384.74   \n",
              "2  072d7ad4-7aa7-4e12-b4f0-e6f942bb0709      588  4696.77   \n",
              "3  243e6d3b-3268-4662-a494-b76100ef8a33      658  3598.41   \n",
              "4  bc283fe1-69fa-4055-a2fb-b1286c2e932e     6581  2067.84   \n",
              "\n",
              "             timestamp      merchant   category         location  \\\n",
              "0  2025-02-15 15:38:38          Uber     Travel  Jenniferchester   \n",
              "1  2025-01-08 21:15:15  CVS Pharmacy     Health   East Katherine   \n",
              "2  2025-01-12 05:20:56        Costco  Groceries        Davidstad   \n",
              "3  2025-03-14 01:00:39          Uber     Travel    South Brandon   \n",
              "4  2025-03-11 19:24:14      Chipotle     Dining      Austinhaven   \n",
              "\n",
              "        ip_address  browser device_type  \\\n",
              "0  183.141.185.242   Chrome     Desktop   \n",
              "1  155.102.247.225  Firefox      Tablet   \n",
              "2      1.208.9.139    Brave      Mobile   \n",
              "3   135.111.80.184  Firefox     Desktop   \n",
              "4   122.148.188.96   Safari      Tablet   \n",
              "\n",
              "                                    session_metadata  fraud_flag  \n",
              "0  Latency: 71ms | Device: Desktop | Browser: Chrome           0  \n",
              "1  Latency: 95ms | Device: Tablet | Browser: Firefox           0  \n",
              "2   Latency: 303ms | Device: Mobile | Browser: Brave           0  \n",
              "3  Latency: 177ms | Device: Desktop | Browser: Fi...           0  \n",
              "4  Latency: 325ms | Device: Tablet | Browser: Safari           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de4f8eae-4685-4bfa-ae46-c90bff6a33e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>amount</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>location</th>\n",
              "      <th>ip_address</th>\n",
              "      <th>browser</th>\n",
              "      <th>device_type</th>\n",
              "      <th>session_metadata</th>\n",
              "      <th>fraud_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fc12e211-cd56-4394-a4c6-dc1c360b4ff4</td>\n",
              "      <td>1956</td>\n",
              "      <td>4105.52</td>\n",
              "      <td>2025-02-15 15:38:38</td>\n",
              "      <td>Uber</td>\n",
              "      <td>Travel</td>\n",
              "      <td>Jenniferchester</td>\n",
              "      <td>183.141.185.242</td>\n",
              "      <td>Chrome</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Latency: 71ms | Device: Desktop | Browser: Chrome</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13f84663-5bc5-4b5f-9146-eb42c2e63876</td>\n",
              "      <td>8666</td>\n",
              "      <td>4384.74</td>\n",
              "      <td>2025-01-08 21:15:15</td>\n",
              "      <td>CVS Pharmacy</td>\n",
              "      <td>Health</td>\n",
              "      <td>East Katherine</td>\n",
              "      <td>155.102.247.225</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>Latency: 95ms | Device: Tablet | Browser: Firefox</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>072d7ad4-7aa7-4e12-b4f0-e6f942bb0709</td>\n",
              "      <td>588</td>\n",
              "      <td>4696.77</td>\n",
              "      <td>2025-01-12 05:20:56</td>\n",
              "      <td>Costco</td>\n",
              "      <td>Groceries</td>\n",
              "      <td>Davidstad</td>\n",
              "      <td>1.208.9.139</td>\n",
              "      <td>Brave</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>Latency: 303ms | Device: Mobile | Browser: Brave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>243e6d3b-3268-4662-a494-b76100ef8a33</td>\n",
              "      <td>658</td>\n",
              "      <td>3598.41</td>\n",
              "      <td>2025-03-14 01:00:39</td>\n",
              "      <td>Uber</td>\n",
              "      <td>Travel</td>\n",
              "      <td>South Brandon</td>\n",
              "      <td>135.111.80.184</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>Latency: 177ms | Device: Desktop | Browser: Fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bc283fe1-69fa-4055-a2fb-b1286c2e932e</td>\n",
              "      <td>6581</td>\n",
              "      <td>2067.84</td>\n",
              "      <td>2025-03-11 19:24:14</td>\n",
              "      <td>Chipotle</td>\n",
              "      <td>Dining</td>\n",
              "      <td>Austinhaven</td>\n",
              "      <td>122.148.188.96</td>\n",
              "      <td>Safari</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>Latency: 325ms | Device: Tablet | Browser: Safari</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de4f8eae-4685-4bfa-ae46-c90bff6a33e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de4f8eae-4685-4bfa-ae46-c90bff6a33e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de4f8eae-4685-4bfa-ae46-c90bff6a33e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c410f0c-3a88-414c-a7c2-20a5f550b1d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c410f0c-3a88-414c-a7c2-20a5f550b1d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c410f0c-3a88-414c-a7c2-20a5f550b1d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "Toe0ZQ0HjvPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53wMsQLdjugO",
        "outputId": "4459ba0e-e98f-4fd7-ba1d-2c75f50502a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "bgWH2MuGj44u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fquwRwhGkACt",
        "outputId": "3e33d23c-c8a8-434f-ed71-68db4940282a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"synthetic_transactions.csv\")\n",
        "\n",
        "# Initialize NLP tools\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "xIbGB9UkkC5t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
        "    words = word_tokenize(text)  # Tokenize text\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatize & remove stopwords\n",
        "    return \" \".join(words)"
      ],
      "metadata": {
        "id": "kIE1zzuBkK4g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to transaction descriptions\n",
        "df[\"cleaned_description\"] = df[\"merchant\"] + \" \" + df[\"location\"] + \" \" + df[\"category\"] + \" $\" + df[\"amount\"].astype(str)\n",
        "df[\"cleaned_description\"] = df[\"cleaned_description\"].astype(str).apply(preprocess_text)\n",
        "\n",
        "# Save cleaned dataset\n",
        "df.to_csv(\"cleaned_transactions.csv\", index=False)"
      ],
      "metadata": {
        "id": "vY1SZ8TIkNTY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "AbAT9FiGkld7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1qv_81nkmx6",
        "outputId": "3d236bbc-e1bb-414a-c022-16a127d5dd53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "qBKN5KY_kozz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save descriptions to a text file (required for SentencePiece training)\n",
        "with open(\"descriptions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for desc in df[\"cleaned_description\"]:\n",
        "        f.write(desc + \"\\n\")\n",
        "\n",
        "# Train SentencePiece tokenizer\n",
        "spm.SentencePieceTrainer.train(input=\"descriptions.txt\", model_prefix=\"tokenizer\", vocab_size=5000)"
      ],
      "metadata": {
        "id": "M3X5fAMzkrD5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained tokenizer\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"tokenizer.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ8DTW5ukuvL",
        "outputId": "da2919fd-4040-4823-c42d-f30e8696bf83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all transactions\n",
        "df[\"tokenized_description\"] = df[\"cleaned_description\"].apply(lambda x: sp.encode_as_pieces(str(x)))\n",
        "\n",
        "# Save dataset with tokenized descriptions\n",
        "df.to_csv(\"tokenized_transactions.csv\", index=False)"
      ],
      "metadata": {
        "id": "0i-F21Qtu0JB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec embedding**"
      ],
      "metadata": {
        "id": "4oVNfVZk2sqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqWDJOpr05pb",
        "outputId": "c875f197-1dc6-4911-f8f2-55d67e1ebafc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import ast  # To safely convert string tokens back into lists\n",
        "\n",
        "# Load tokenized dataset\n",
        "df = pd.read_csv(\"tokenized_transactions.csv\")\n",
        "\n",
        "# Convert tokenized text from string to list\n",
        "df[\"tokenized_description\"] = df[\"tokenized_description\"].apply(ast.literal_eval)\n",
        "\n",
        "# Prepare tokenized sentences for training\n",
        "sentences = df[\"tokenized_description\"].tolist()\n",
        "\n",
        "# Train Word2Vec Model\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "w2v_model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "PYAYACmn0-ze"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained Word2Vec model\n",
        "w2v_model = Word2Vec.load(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "ZABjG3k42iYW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get embedding for a transaction\n",
        "def get_embedding(tokens, model):\n",
        "    embeddings = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if len(embeddings) == 0:\n",
        "        return np.zeros(model.vector_size)  # Return zero vector if no valid words\n",
        "    return np.mean(embeddings, axis=0)  # Take the mean of word embeddings"
      ],
      "metadata": {
        "id": "15Cz_mEO2lNV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply embedding extraction\n",
        "df[\"word2vec_embedding\"] = df[\"tokenized_description\"].apply(lambda x: get_embedding(x, w2v_model).tolist())\n",
        "\n",
        "# Save dataset with embeddings\n",
        "df.to_csv(\"word2vec_transactions.csv\", index=False)"
      ],
      "metadata": {
        "id": "ka4tRX9W2nmu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoencoder**"
      ],
      "metadata": {
        "id": "jx5yHRSw38i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZGxPV8q26rW",
        "outputId": "c510097d-1f92-4edb-a643-57930b57b4ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "metadata": {
        "id": "5gQQDWSt4All"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"word2vec_transactions.csv\")\n",
        "\n",
        "# Print available columns\n",
        "print(\"Available Columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xhTkXO74nYT",
        "outputId": "529e275a-cda9-432f-bd77-48e37816fc55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Columns: ['transaction_id', 'user_id', 'amount', 'timestamp', 'merchant', 'category', 'location', 'ip_address', 'browser', 'device_type', 'session_metadata', 'fraud_flag', 'cleaned_description', 'tokenized_description', 'word2vec_embedding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"word2vec_transactions.csv\")\n",
        "\n",
        "# Select numerical features\n",
        "numerical_features = [\"amount\"]  # Modify as needed\n",
        "X = df[numerical_features].values.astype(\"float32\")\n",
        "\n",
        "# Normalize data\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "# Define AutoEncoder model\n",
        "encoding_dim = 5  # Compressed feature size\n",
        "input_dim = X.shape[1]\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "decoded = Dense(input_dim, activation=\"sigmoid\")(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train AutoEncoder\n",
        "autoencoder.fit(X, X, epochs=20, batch_size=256, shuffle=True, verbose=1)\n",
        "\n",
        "# Extract encoded (low-dimensional) features\n",
        "encoder = keras.Model(input_layer, encoded)\n",
        "structured_embeddings = encoder.predict(X)\n",
        "\n",
        "# Save embeddings\n",
        "np.save(\"structured_embeddings.npy\", structured_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33kTtb5o4FNZ",
        "outputId": "5707b19e-3531-426e-8e66-8e1ae076f8d4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.8404\n",
            "Epoch 2/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.6443\n",
            "Epoch 3/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.6390\n",
            "Epoch 4/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6377\n",
            "Epoch 5/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.6381\n",
            "Epoch 6/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6322\n",
            "Epoch 7/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6412\n",
            "Epoch 8/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.6288\n",
            "Epoch 9/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6323\n",
            "Epoch 10/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6339\n",
            "Epoch 11/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6383\n",
            "Epoch 12/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6390\n",
            "Epoch 13/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.6370\n",
            "Epoch 14/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6345\n",
            "Epoch 15/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6315\n",
            "Epoch 16/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6361\n",
            "Epoch 17/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.6414\n",
            "Epoch 18/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6332\n",
            "Epoch 19/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6357\n",
            "Epoch 20/20\n",
            "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.6382\n",
            "\u001b[1m31250/31250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz3TV7Z94MFy",
        "outputId": "c0c277c2-2ece-4af3-ad2c-ea1965dbcdce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "yAWQRa4e4Xso"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load structured embeddings\n",
        "structured_embeddings = np.load(\"structured_embeddings.npy\")\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=3)  # Reduce to 3D for visualization\n",
        "pca_features = pca.fit_transform(structured_embeddings)\n",
        "\n",
        "# Save PCA-transformed data\n",
        "np.save(\"pca_embeddings.npy\", pca_features)"
      ],
      "metadata": {
        "id": "hP1SV-8j4aCP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If using PyTorch, clear CUDA memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# If using TensorFlow, reset session\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "g1sl6BeMKcQ0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete large variables\n",
        "del  structured_embeddings\n",
        "\n",
        "# Manually trigger garbage collection\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6PuB2B3UPb5",
        "outputId": "f82cc561-4c82-4381-98fe-54f932b1eb62"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "volpr6tBfL5V",
        "outputId": "57a2b652-9345-40f4-baee-5c5de622ec7f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss"
      ],
      "metadata": {
        "id": "LLzllenyfUj2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load structured embeddings\n",
        "structured_embeddings = np.load(\"pca_embeddings.npy\").astype(\"float32\")\n",
        "\n",
        "# Ensure embeddings are C-contiguous\n",
        "structured_embeddings = np.ascontiguousarray(structured_embeddings)\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "faiss.normalize_L2(structured_embeddings)\n",
        "\n",
        "# Initialize FAISS index for Cosine Similarity\n",
        "d = structured_embeddings.shape[1]  # Number of dimensions\n",
        "index = faiss.IndexFlatIP(d)  # Inner Product (Cosine Similarity)\n",
        "\n",
        "# Add embeddings to FAISS index\n",
        "index.add(structured_embeddings)\n",
        "\n",
        "# Save FAISS index\n",
        "faiss.write_index(index, \"faiss_fraud_index.idx\")"
      ],
      "metadata": {
        "id": "HQo6y0KMfXaM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FAISS index\n",
        "index = faiss.read_index(\"faiss_fraud_index.idx\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"word2vec_transactions.csv\")\n",
        "\n",
        "# Load structured embeddings\n",
        "structured_embeddings = np.load(\"pca_embeddings.npy\").astype(\"float32\")"
      ],
      "metadata": {
        "id": "X1gj3unkfb7s"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define anomaly detection function\n",
        "def detect_anomalies(embeddings, threshold=0.3, k=5):\n",
        "    \"\"\"\n",
        "    Detect transactions that are anomalous based on similarity search.\n",
        "    - threshold: Lower cosine similarity means more anomalous.\n",
        "    - k: Number of nearest neighbors to consider.\n",
        "    \"\"\"\n",
        "    anomalies = []\n",
        "\n",
        "    for i, emb in enumerate(embeddings):\n",
        "        query = emb.reshape(1, -1)\n",
        "        distances, _ = index.search(query, k)\n",
        "\n",
        "        # Get the average similarity score\n",
        "        avg_similarity = np.mean(distances)  # Closer to 1 = similar, closer to 0 = anomalous\n",
        "\n",
        "        # Flag as fraud if similarity is too low\n",
        "        if avg_similarity < threshold:\n",
        "            anomalies.append((i, avg_similarity))\n",
        "\n",
        "    return anomalies"
      ],
      "metadata": {
        "id": "BZtCoqe6fz0E"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect anomalies with a lower similarity threshold\n",
        "anomalies = detect_anomalies(structured_embeddings, threshold=0.3, k=5)\n",
        "\n",
        "# Save suspicious transactions\n",
        "anomalous_indices = [a[0] for a in anomalies]\n",
        "anomalous_transactions = df.iloc[anomalous_indices]\n",
        "anomalous_transactions.to_csv(\"flagged_anomalies.csv\", index=False)"
      ],
      "metadata": {
        "id": "BoljyF0wf6Mm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}